文章来源：[diagoal德哥PostgreSQL数据库开发规范]

# 一、稳定性与性能规范

【强制】在代码中写分页查询逻辑时，若count为0应直接返回，避免执行后面的分页语句。

【强制】游标使用后要及时关闭。

【强制】两阶段提交的事务，要及时提交或回滚，否则可能导致数据库膨胀。

【强制】不要使用delete 全表，性能很差，请使用truncate代替，（truncate是DDL语句，注意加锁等待超时）。

【强制】应用程序一定要开启autocommit，同时避免应用程序自动begin事务，并且不进行任何操作的情况发生，某些框架可能会有这样的问题。

【强制】高并发的应用场合，务必使用绑定变量(prepared statement)，防止数据库硬解析消耗过多的CPU资源。

【强制】不要使用hash index，目前hash index不写REDO，在备库只有结构，没有数据，并且数据库crash后无法恢复。
 同时不建议使用unlogged table ，道理同上，但是如果你的数据不需要持久化，则可以考虑使用unlogged table来提升数据的写入和修改性能。

【强制】秒杀场景，一定要使用 advisory_lock先对记录的唯一ID进行锁定，拿到AD锁再去对数据进行更新操作。 拿不到锁时，可以尝试重试拿锁。
 例如

```plsql
CREATE OR REPLACE FUNCTION public.f(i_id integer)    
 RETURNS void    
 LANGUAGE plpgsql    
AS $function$   
declare   
  a_lock boolean := false;  
begin   
  select pg_try_advisory_xact_lock(i_id) into a_lock;  
  拿到锁，更新  
  if a_lock then  
    update t1 set count=count-1 where id=i_id;   
  end if;  
  exception when others then    
    return;   
end;   
$function$;    
select f(id) from tbl where id=? and count>0;  
```

可以再根据实际情况设计，原理如上即可。
 函数可以如返回布尔，或者唯一ID，或者数字等。

【强制】在函数中，或程序中，不要使用count(`*`)判断是否有数据，很慢。 建议的方法是limit 1;
 例如

```plsql
select 1 from tbl where xxx limit 1;  
if found -- 存在  
else  -- 不存在  
```

【强制】对于高并发的应用场景，务必使用程序的连接池，否则性能会很低下。
 如果程序没有连接池，建议在应用层和数据库之间架设连接池，例如使用pgbouncer或者pgpool-II作为连接池。

【强制】程序务必有重连机制，如果没有重连机制，一个长期空闲的连接可能会被网络层设备当成无效会话强制中断掉。即使设置tcp_keepalives_idle,tcp_keepalives_interval,tcp_keepalives_count等较短的TCP心跳，也不一定能覆盖所有场景。
 建议有重连机制，建议在使用长时间未被使用的连接前使用select 1;探测一下是否连接正常，如果不正常，则重连。建议使用select 1;作为连接的定期心跳。

【强制】当业务有近邻查询的需求时，务必对字段建立GIST或SP-GIST索引，加速近邻查询的需求。
 例如

```plsql
create index idx on tbl using gist(col);  
select * from tbl order by col <-> '(0,100)';  
```

【强制】避免频繁创建和删除临时表，以减少系统表资源的消耗，因为创建临时表会产生元数据，频繁创建，元数据可能会出现碎片。

【强制】必须选择合适的事务隔离级别，不要使用越级的隔离级别，例如READ COMMITTED可以满足时，就不要使用repeatable read和serializable隔离级别。

【推荐】高峰期对大表添加包含默认值的字段，会导致表的rewrite，建议只添加不包含默认值的字段，业务逻辑层面后期处理默认值。

【推荐】在使用空间查询时，点面包含、相交等查询，为了提升效率，尽量使用有效面积大的多边形，如果做不到，可以先对多边形进行split，同时使用union all合并结果。

[《PostgreSQL 空间切割(st_split)功能扩展 - 空间对象网格化 (多边形GiST优化)》](https://github.com/digoal/blog/blob/master/201710/20171005_01.md)

[《PostgreSQL 空间st_contains，st_within空间包含搜索优化 - 降IO和降CPU(bound box) (多边形GiST优化)》](https://github.com/digoal/blog/blob/master/201710/20171004_01.md)

[《PostgreSQL 黑科技 - 空间聚集存储, 内窥GIN, GiST, SP-GiST索引》](https://github.com/digoal/blog/blob/master/201709/20170905_01.md)

[《PostgreSQL multipolygon 空间索引查询过滤精简优化 - IO，CPU放大优化》](https://github.com/digoal/blog/blob/master/201711/20171122_03.md)

【推荐】分页评估，不需要精确分页数时，请使用快速评估分页数的方法。
https://yq.aliyun.com/articles/39682
 例如

```plsql
CREATE OR REPLACE FUNCTION countit(text)                    
RETURNS float4           
LANGUAGE plpgsql AS          
$$DECLARE               
    v_plan json;                
BEGIN                      
    EXECUTE 'EXPLAIN (FORMAT JSON) '||$1                                
        INTO v_plan;                                                                       
    RETURN v_plan #>> '{0,Plan,"Plan Rows"}';  
END;  
$$;  
postgres=# create table t1234(id int, info text);  
CREATE TABLE  
postgres=# insert into t1234 select generate_series(1,1000000),'test';  
INSERT 0 1000000  
postgres=# analyze t1234;  
ANALYZE  
postgres=# select countit('select * from t1234 where id<1000');  
 countit   
---------  
     954  
(1 row)  
postgres=# select countit('select * from t1234 where id between 1 and 1000 or (id between 100000 and 101000)');  
 countit   
---------  
   1931  
(1 row)  
```

【推荐】分页优化，建议通过游标返回分页结果，避免越后面的页返回越慢的情况。
 例如

```plsql
postgres=# declare cur1 cursor for select * from sbtest1 where id between 100 and 1000000 order by id;  
DECLARE CURSOR  
Time: 0.422 ms  
```

获取数据

```plsql
postgres=# fetch 100 from cur1;  
。。。  
```

如果要前滚页，加SCROLL打开游标

```plsql
declare cur1 SCROLL cursor for select * from sbtest1 where id between 100 and 1000000 order by id;  
```

【推荐】可以预估SQL执行时间的操作，建议设置语句级别的超时，可以防止雪崩，也可以防止长时间持锁。
 例如设置事务中执行的每条SQL超时时间为10秒

```plsql
begin;  
set local statement_timeout = '10s';  
-- query;  
end;  
```

【推荐】TRUNCATE TABLE 在功能上与不带 WHERE 子句的 DELETE 语句相同：二者均删除表中的全部行。但  TRUNCATE TABLE 比 DELETE  速度快，且使用的系统和事务日志资源少，但是TRUNCATE是DDL，锁粒度很大，故不建议在开发代码中使用DDL语句，除非加了lock_timeout锁超时的会话参数或事务参数。

【推荐】PostgreSQL支持DDL事务，支持回滚DDL，建议将DDL封装在事务中执行，必要时可以回滚，但是需要注意事务的长度，避免长时间堵塞DDL对象的读操作。

【推荐】如果用户需要在插入数据和，删除数据前，或者修改数据后马上拿到插入或被删除或修改后的数据，建议使用insert into ..  returning ..; delete .. returning ..或update .. returning ..;  语法。减少数据库交互次数。
 例如

```plsql
postgres=# create table tbl4(id serial, info text);  
CREATE TABLE  
postgres=# insert into tbl4 (info) values ('test') returning *;  
 id | info   
----+------  
  1 | test  
(1 row)  
INSERT 0 1  
postgres=# update tbl4 set info='abc' returning *;  
 id | info   
----+------  
  1 | abc  
(1 row)  
UPDATE 1  
postgres=# delete from tbl4 returning *;  
 id | info   
----+------  
  1 | abc  
(1 row)  
DELETE 1  
```

【推荐】自增字段建议使用序列，序列分为2字节，4字节，8字节几种(serial2,serial4,serial8)。按实际情况选择。 禁止使用触发器产生序列值。
 例如

```plsql
postgres=# create table tbl4(id serial, info text);  
CREATE TABLE  
```

【推荐】如果对全表的很多字段有任意字段匹配的查询需求，建议使用行级别全文索引，或行转数组的数组级别索引。
 例如

```plsql
select * from t where phonenum='digoal' or info ~ 'digoal' or c1='digoal' or ......;  
```

更正为

```plsql
postgres=# create or replace function f1(text) returns tsvector as $$            
select to_tsvector($1);     
$$ language sql immutable strict;  
CREATE FUNCTION  
postgres=# alter function record_out(record) immutable;  
ALTER FUNCTION  
postgres=# alter function textin(cstring) immutable;  
ALTER FUNCTION  
postgres=# create index idx_t_1 on t using gin (f1('jiebacfg'::regconfig,t::text)) ;  
CREATE INDEX  
postgres=# select * from t where f1('jiebacfg'::regconfig,t::text) @@ to_tsquery('digoal & post') ;  
 phonenum | info | c1 | c2 | c3 | c4   
----------+------+----+----+----+----  
(0 rows)  
postgres=# select * from t where f1('jiebacfg'::regconfig,t::text) @@ to_tsquery('digoal & china') ;  
  phonenum   |            info             | c1  |  c2   |              c3              |             c4               
-------------+-----------------------------+-----+-------+------------------------------+----------------------------  
 13888888888 | i am digoal, a postgresqler | 123 | china | 中华人民共和国，阿里巴巴，阿 | 2016-04-19 11:15:55.208658  
(1 row)  
postgres=# select * from t where f1('jiebacfg'::regconfig,t::text) @@ to_tsquery('digoal & 阿里巴巴') ;  
  phonenum   |            info             | c1  |  c2   |              c3              |             c4               
-------------+-----------------------------+-----+-------+------------------------------+----------------------------  
 13888888888 | i am digoal, a postgresqler | 123 | china | 中华人民共和国，阿里巴巴，阿 | 2016-04-19 11:15:55.208658  
(1 row)  
postgres=# explain select * from t where f1('jiebacfg'::regconfig,t::text) @@ to_tsquery('digoal & 阿里巴巴') ;  
                                             QUERY PLAN                                                
------------------------------------------------------------------------------------------------------  
 Seq Scan on t  (cost=0.00..1.52 rows=1 width=140)  
   Filter: (to_tsvector('jiebacfg'::regconfig, (t.*)::text) @@ to_tsquery('digoal & 阿里巴巴'::text))  
(2 rows)  
```

【推荐】中文分词的token mapping一定要设置，否则对应的token没有词典进行处理。
 例如

```plsql
ALTER TEXT SEARCH CONFIGURATION testzhcfg ADD MAPPING FOR a,b,c,d,e,f,g,h,i,j,k,l,m,n,o,p,q,r,s,t,u,v,w,x,y,z WITH simple;
```

zhparser分词插件的其他配置

```plsql
zhparser.punctuation_ignore = f
zhparser.seg_with_duality = f
zhparser.dict_in_memory = f
zhparser.multi_short = f
zhparser.multi_duality = f
zhparser.multi_zmain = f
zhparser.multi_zall = f
```

参考
https://yq.aliyun.com/articles/7730
http://www.xunsearch.com/scws/docs.php#libscws

【推荐】树形查询应该使用递归查询，尽量减少数据库的交互或JOIN。
 例如

```plsql
CREATE TABLE TBL_TEST  
(  
ID    numeric,  
NAME text,  
PID   numeric                                  DEFAULT 0  
);  
INSERT INTO TBL_TEST(ID,NAME,PID) VALUES('1','10','0');  
INSERT INTO TBL_TEST(ID,NAME,PID) VALUES('2','11','1');  
INSERT INTO TBL_TEST(ID,NAME,PID) VALUES('3','20','0');  
INSERT INTO TBL_TEST(ID,NAME,PID) VALUES('4','12','1');  
INSERT INTO TBL_TEST(ID,NAME,PID) VALUES('5','121','2');  
```

从Root往树末梢递归

```plsql
with recursive t_result as (  
  select * from tbl_test where id=1  
    union all  
  select t2.* from t_result t1 join tbl_test t2 on t1.id=t2.pid  
)  
select * from t_result;  
 id | name | pid   
----+------+-----  
  1 | 10   |   0  
  2 | 11   |   1  
  4 | 12   |   1  
  5 | 121  |   2  
(4 rows)  
```

从末梢往树ROOT递归

```plsql
with recursive t_result as (  
  select * from tbl_test where id=5  
    union all  
  select t2.* from t_result t1 join tbl_test t2 on t1.pid=t2.id  
)  
select * from t_result;  
 id | name | pid   
----+------+-----  
  5 | 121  |   2  
  2 | 11   |   1  
  1 | 10   |   0  
(3 rows)  
```

树形结构的注意事项
 \1. 一定要能跳出循环，即循环子句查不到结果为止。
 \2. 树形结构如果有多个值，则会出现查到的结果比实际的多的情况，这个业务上是需要保证不出现重复的。

【推荐】应尽量避免长事务，长事务可能造成垃圾膨胀。

【推荐】如果业务有多个维度的分析需求，应该尽量使用PostgreSQL的多维分析语法，减少数据的重复扫描。
 支持的多维分析语法包括
 GROUPING SETS, CUBE, ROLLUP

例如
 假设有4个业务字段，一个时间字段。

```plsql
postgres=# create table tab5(c1 int, c2 int, c3 int, c4 int, crt_time timestamp);  
CREATE TABLE  
```

生成一批测试数据

```plsql
postgres=# insert into tab5 select   
trunc(100*random()),   
trunc(1000*random()),   
trunc(10000*random()),   
trunc(100000*random()),   
clock_timestamp() + (trunc(10000*random())||' hour')::interval   
from generate_series(1,1000000);  
INSERT 0 1000000  
postgres=# select * from tab5 limit 10;  
 c1 | c2  |  c3  |  c4   |          crt_time            
----+-----+------+-------+----------------------------  
 72 |  46 | 3479 | 20075 | 2017-02-02 14:56:36.854218  
 98 | 979 | 4491 | 83012 | 2017-06-13 08:56:36.854416  
 54 | 758 | 5838 | 45956 | 2016-09-18 02:56:36.854427  
  3 |  67 | 5148 | 74754 | 2017-01-01 01:56:36.854431  
 42 | 650 | 7681 | 36495 | 2017-06-20 15:56:36.854435  
  4 | 472 | 6454 | 19554 | 2016-06-18 19:56:36.854438  
 82 | 922 |  902 | 17435 | 2016-07-21 14:56:36.854441  
 68 | 156 | 1028 | 13275 | 2017-07-16 10:56:36.854444  
  0 | 674 | 7446 | 59386 | 2016-07-26 09:56:36.854447  
  0 | 629 | 2022 | 52285 | 2016-11-04 13:56:36.85445  
(10 rows)  
```

创建一个统计结果表, 其中bitmap表示统计的字段组合, 用位置符0,1表示是否统计了该维度

```plsql
create table stat_tab5 (c1 int, c2 int, c3 int, c4 int, time1 text, time2 text, time3 text, time4 text, cnt int8, bitmap text); 
```

生成业务字段任意维度组合+4组时间任选一组的组合统计
 PS (如果业务字段有空的情况，建议统计时用coalesce转一下，确保不会统计到空的情况)

```plsql
insert into stat_tab5  
select c1,c2,c3,c4,t1,t2,t3,t4,cnt,   
'' ||   
case when c1 is null then 0 else 1 end ||   
case when c2 is null then 0 else 1 end ||   
case when c3 is null then 0 else 1 end ||   
case when c4 is null then 0 else 1 end ||   
case when t1 is null then 0 else 1 end ||   
case when t2 is null then 0 else 1 end ||   
case when t3 is null then 0 else 1 end ||   
case when t4 is null then 0 else 1 end  
from   
(  
select c1,c2,c3,c4,  
to_char(crt_time, 'yyyy') t1,   
to_char(crt_time, 'yyyy-mm') t2,   
to_char(crt_time, 'yyyy-mm-dd') t3,   
to_char(crt_time, 'yyyy-mm-dd hh24') t4,   
count(*) cnt  
from tab5   
group by   
cube(c1,c2,c3,c4),   
grouping sets(to_char(crt_time, 'yyyy'), to_char(crt_time, 'yyyy-mm'), to_char(crt_time, 'yyyy-mm-dd'), to_char(crt_time, 'yyyy-mm-dd hh24'))  
)  
t;  
INSERT 0 49570486  
Time: 172373.714 ms  
```

在bitmap上创建索引方便取数据

```plsql
create index idx_stat_tab5_bitmap on stat_tab5 (bitmap);  
```

用户勾选几个维度，取出数据

```plsql
c1,c3,c4,t3 = bitmap(10110010)  
postgres=# select c1,c3,c4,time3,cnt from stat_tab5 where bitmap='10110010' limit 10;  
 c1 | c3 |  c4   |   time3    | cnt   
----+----+-------+------------+-----  
 41 |  0 | 30748 | 2016-06-04 |   1  
 69 |  0 | 87786 | 2016-06-04 |   1  
 70 |  0 | 38805 | 2016-06-04 |   1  
 79 |  0 | 65892 | 2016-06-08 |   1  
 51 |  0 | 13615 | 2016-06-11 |   1  
 47 |  0 | 42196 | 2016-06-28 |   1  
 45 |  0 | 54736 | 2016-07-01 |   1  
 50 |  0 | 21605 | 2016-07-02 |   1  
 46 |  0 | 40888 | 2016-07-16 |   1  
 41 |  0 | 90258 | 2016-07-17 |   1  
(10 rows)  
Time: 0.528 ms  
postgres=# select * from stat_tab5 where bitmap='00001000' limit 10;  
 c1 | c2 | c3 | c4 | time1 | time2 | time3 | time4 |  cnt   |  bitmap    
----+----+----+----+-------+-------+-------+-------+--------+----------  
    |    |    |    | 2016  |       |       |       | 514580 | 00001000  
    |    |    |    | 2017  |       |       |       | 485420 | 00001000  
(2 rows)  
Time: 0.542 ms  
```

【推荐】对于有UV查询需求的场景（例如count(distinct xx) where time between xx and xx），如果要求非常快的响应速度，但是对精确度要求不高时，建议可以使用PostgreSQL的估值数据类型HLL。
 例如

```plsql
create table access_date (acc_date date unique, userids hll);  
insert into access_date select current_date, hll_add_agg(hll_hash_integer(user_id)) from generate_series(1,10000) t(user_id);  
select *, total_users-coalesce(lag(total_users,1) over (order by rn),0) AS new_users  
FROM  
(  
  SELECT acc_date, row_number() over date as rn,#hll_union_agg(userids) OVER date as total_users   
    FROM access_date  
  WINDOW date AS (ORDER BY acc_date ASC ROWS UNBOUNDED PRECEDING)  
) t;  
```

【推荐】PostgreSQL 的insert on conflict语法如下

```plsql
INSERT INTO table_name [ AS alias ] [ ( column_name [, ...] ) ]  
    { DEFAULT VALUES | VALUES ( { expression | DEFAULT } [, ...] ) [, ...] | query }  
    [ ON CONFLICT [ conflict_target ] conflict_action ]  
where conflict_target can be one of:  
    ( { index_column_name | ( index_expression ) } [ COLLATE collation ] [ opclass ] [, ...] ) [ WHERE index_predicate ]  
    ON CONSTRAINT constraint_name  
and conflict_action is one of:  
    DO NOTHING  
    DO UPDATE SET { column_name = { expression | DEFAULT } |  
                    ( column_name [, ...] ) = ( { expression | DEFAULT } [, ...] ) |  
                    ( column_name [, ...] ) = ( sub-SELECT )  
                  } [, ...]  
              [ WHERE condition ]  
```

例如

```plsql
postgres=# insert into tbl values (1,'info') on conflict on constraint tbl_pkey do update set info=excluded.info;  
INSERT 0 1  
```

【推荐】如果用户经常需要访问一张大表的某些数据，为了提升效率可以使用索引，但是如果这个数据还需要被用于更复杂的与其他表的JOIN操作，则可以使用物化视图来提升性能。
 同时物化视图还可以被用于OLAP场景，例如统计后的数据可以固化到物化视图中，以便快速的检索。
 例如

```plsql
CREATE MATERIALIZED VIEW mv_tbl as select xx,xx,xx from tbl where xxx with data;  
```

增量刷新物化视图

```plsql
REFRESH MATERIALIZED VIEW CONCURRENTLY mv_tbl with data;  
```

【推荐】不建议对宽表频繁的更新，原因是PG目前的引擎是多版本的，更新后会产生新的版本，如果对宽表的某几个少量的字段频繁更新，其实是存在写放大的。
 建议将此类宽表的不更新或更新不频繁的列与频繁更新的列拆分成两张表，通过PK进行关联。
 查询是通过PK关联查询出结果即可。

【推荐】使用窗口查询减少数据库和应用的交互次数。
 例如
 有一个这样的表，记录如下:

```plsql
id | company | product 
----+---------+---------
1 | c1      | p1
1 | c1      | p2
1 | b1      | p2
1 | c2      | p2
1 | c1      | p1
2 | c3      | p3
```

需要找出某个产品，这个产品只有一个公司生产。

```plsql
select distinct product from (select min(company) over(partition by product) m1,max(company) over(partition by product) m2, product from tbl) t where m2<>m1; 
```

又如，根据指定窗口，查询当前行与以窗口为范围取其avg,max,min,sum,count,offset,rank,dist等，同时输出当前行。例如与第一名的差距，与前一名的差距，与全国第一名的差距，与全班第一名的差距，同时还输出当前记录的详情。

【推荐】应该尽量在业务层面避免死锁的产生，例如一个用户的数据，尽量在一个线程内处理，而不要跨线程（即跨数据库会话处理）。

【推荐】OLTP系统不要频繁的使用聚合操作，聚合操作消耗较大的CPU与IO资源。例如实时的COUNT操作，如果并发很高，可能导致CPU资源撑爆。
 对于实时性要求不高的场景，可以使用定期操作COUNT，并将COUNT数据缓存在缓存系统中的方式。

【推荐】数据去重的方法，当没有UK或PK时，如果数据出现了重复，有什么好的方法去重。或者某个列没有加唯一约束，但是业务层没有保证唯一，如何去重？
 行级别去重

```plsql
delete from tbl where ctid not in (select min(ctid) from tbl group by tbl::text);  
```

带PK的列col级别去重

```plsql
delete from tbl where pk in (select pk from (select pk,row_number() over(partition by col order by pk) rn from tbl) t where t.rn>1);  
```

不带PK的列级别去重(以业务逻辑为准，可以选择其他的条件删除)

```plsql
delete from tbl where ctid not in (select min(ctid) from tbl group by col);  
```

【推荐】快速读取随机记录的方法 利用索引列进行优化的方法。
 方法 1. 随机取出n条记录,以下取出5条随机记录

```plsql
digoal=> select * from tbl_user
digoal->  where id in
digoal->         (select floor(random() * (max_id - min_id))::int
digoal(>                 + min_id
digoal(>            from generate_series(1,5),
digoal(>                 (select max(id) as max_id,
digoal(>                         min(id) as min_id
digoal(>                    from tbl_user) s1
digoal(>         )
digoal-> limit 5;
   id   | firstname | lastname |   corp   | age 
--------+-----------+----------+----------+-----
 965638 | zhou      | digoal   | sky-mobi |  27
 193491 | zhou      | digoal   | sky-mobi |  27
 294286 | zhou      | digoal   | sky-mobi |  27
 726263 | zhou      | digoal   | sky-mobi |  27
 470713 | zhou      | digoal   | sky-mobi |  27
(5 rows)
Time: 0.670 ms
```

方法 2. 取出N条连续的随机记录.(此处用到函数)

```plsql
digoal=> create or replace function f_get_random (i_range int) returns setof record as $BODY$
digoal$> declare
digoal$> v_result record;
digoal$> v_max_id int;
digoal$> v_min_id int;
digoal$> v_random numeric;
digoal$> begin
digoal$> select random() into v_random;
digoal$> select max(id),min(id) into v_max_id,v_min_id from tbl_user;
digoal$> for v_result in select * from tbl_user where id between (v_min_id+(v_random*(v_max_id-v_min_id))::int) and (v_min_id+(v_random*(v_max_id-v_min_id))::int+i_range)
digoal$> loop
digoal$> return next v_result;
digoal$> end loop;
digoal$> return;
digoal$> end
digoal$> $BODY$ language plpgsql;
CREATE FUNCTION
```

以下举例取出10条连续的随机记录

```plsql
digoal=> select * from f_get_random(9) as (id bigint,firstname varchar(32),lastname varchar(32),corp varchar(32),age smallint);
   id   | firstname | lastname |   corp   | age 
--------+-----------+----------+----------+-----
 694686 | zhou      | digoal   | sky-mobi |  27
 694687 | zhou      | digoal   | sky-mobi |  27
 694688 | zhou      | digoal   | sky-mobi |  27
 694689 | zhou      | digoal   | sky-mobi |  27
 694690 | zhou      | digoal   | sky-mobi |  27
 694691 | zhou      | digoal   | sky-mobi |  27
 694692 | zhou      | digoal   | sky-mobi |  27
 694693 | zhou      | digoal   | sky-mobi |  27
 694694 | zhou      | digoal   | sky-mobi |  27
 694695 | zhou      | digoal   | sky-mobi |  27
(10 rows)
Time: 0.418 ms
```

【推荐】线上表结构的变更包括添加字段，索引操作在业务低峰期进行。

【推荐】OLTP系统，在高峰期或高并发期间 拒绝 长SQL，大事务，大批量。
 说明：
 (1). 长SQL占用大量的数据库时间和资源，占用连接，可能影响正常业务运行。
 (2). 大事务，或长事务，可能导致长时间持锁，与其他事务产生锁冲突。
 (3). 大批量，大批量在并发事务中增加锁等待的几率。

【推荐】查询条件要和索引匹配，例如查询条件是表达式时，索引也要是表达式索引，查询条件为列时，索引就是列索引。

【推荐】如何判断两个值是不是不一样（并且将NULL视为一样的值），使用col1 IS DISTINCT FROM col2
 例如

```plsql
postgres=# select null is distinct from null;
 ?column? 
----------
 f
(1 row)
postgres=# select null is distinct from 1;
 ?column? 
----------
 t
(1 row)
```

另外还有IS NOT DISTINCT FROM的用法 。

【推荐】如果在UDF或online code逻辑中有数据的处理需求时，建议使用游标进行处理。
 例如

```plsql
do language plpgsql $$
declare
  cur refcursor;
  rec record;
begin
  open cur for select * from tbl where id>1; 
  loop
    fetch cur into rec; 
    if found then  
      raise notice '%', rec; 
      update tbl set info='ab' where current of cur;
      -- other query
    else 
      close cur;
      exit; 
    end if;
  end loop;
end;
$$;
```

【推荐】应尽量避免在 where 子句中使用!=或<>操作符，否则将引擎放弃使用索引而进行全表扫描。
 如果业务确实有这种需求的查询，可以有几种优化方法
 \1. partial index
 这个是最有效的方法，可以使用到索引扫描，如果有其他条件，也可以在其他条件的索引上建立partial index.

```plsql
create index idx1 on tbl (id) where cond1 <> xx;
```

\2. 分区表
 使用分区表，如果有!=的查询条件，PostgreSQL会根据分区约束，避免扫描不需要扫描的表。

\3. 约束

```plsql
set constraint_exclusion=on;
exec query;
```

在查询列上有约束的情况下，如果!=或<>与约束违背，则可以提前返回查询，不会扫描表。

【推荐】对于经常变更，或者新增，删除记录的表，应该尽量加快这种表的统计信息采样频率，获得较实时的采样，输出较好的执行计划。
 例如
 当垃圾达到表的千分之五时，自动触发垃圾回收。
 当数据变化达到表的百分之一时，自动触发统计信息的采集。
 当执行垃圾回收时，不等待，当IOPS较好时可以这么设置。

```plsql
postgres=# create table t21(id int, info text) with (
autovacuum_enabled=on, toast.autovacuum_enabled=on, 
autovacuum_vacuum_scale_factor=0.005, toast.autovacuum_vacuum_scale_factor=0.005, 
autovacuum_analyze_scale_factor=0.01, autovacuum_vacuum_cost_delay=0, 
toast.autovacuum_vacuum_cost_delay=0);
CREATE TABLE
```

【推荐】PostgreSQL 对or的查询条件，会使用bitmap or进行索引的过滤，所以不需要改SQL语句，可以直接使用。
 例如
 以下查询都可以走索引

```plsql
select * from tbl where col1 =1 or col1=2 or col2=1 or ...;
select * from tbl where col1 in (1,2);
```

【推荐】很多时候用 exists 代替 in 是一个好的选择：

```plsql
select num from a where num in (select num from b);
```

用下面的语句替换：

```plsql
select num from a where exists(select 1 from b where num=a.num)
```

【推荐】尽量使用数组变量来代替临时表。如果临时表有非常庞大的数据时，才考虑使用临时表。

【推荐】对查询进行优化，应尽量避免全表扫描，首先应考虑在 where 及 order by 涉及的列上建立索引。
 使用explain可以查看执行计划，如果发现执行计划不优，可以通过索引或者调整QUERY的写法解决。
 例如

```plsql
begin;
explain (verbose,costs,timing,buffers,analyze) query;
rollback;
......
```

【推荐】PG优化器可以动态调整JOIN的顺序，获取更好的执行计划，但是如何强制优化器的显示JOIN顺序呢？
 首先PG根据join_collapse_limit的设置，当需要关联的表的个数超过这个设置时，超出的JOIN数部分不会继续动态调整JOIN顺序。
 另外需要注意，如果开启了GEQO，当JOIN的表(含隐式JOIN,以及子查询) (full outer join 只算1)数量超过了geqo_threshold设置的值，则会触发遗传算法，可能无法得到最佳的JOIN顺序。
 要让优化器固定JOIN顺序，首先必须使用显示的JOIN，其次将join_collapse_limit设置为1，显示的JOIN顺序将被固定，固定JOIN顺序可以减少优化器的编排时间，降低频繁执行多表JOIN带来的优化阶段的CPU开销。
 显示的JOIN例子

```plsql
t1 join t2 on (xxx)  
```

隐式的JOIN例子

```plsql
t1, t2 where xxx
```

例如

```plsql
begin;
set local join_collapse_limit=1;
set local geqo=off;
postgres=# create table t1(id int, info text);
CREATE TABLE
postgres=# create table t2(id int, info text);
CREATE TABLE
postgres=# create table t3(id int, info text);
CREATE TABLE
postgres=# create table t4(id int, info text);
CREATE TABLE
postgres=# create table t5(id int, info text);
CREATE TABLE
postgres=# create table t6(id int, info text);
CREATE TABLE
postgres=# create table t7(id int, info text);
CREATE TABLE
JOIN顺序固定为如下
postgres=# explain select * from t2 join t1 using (id) join t3 using (id) join t4 using (id) join t7 using (id) join t6 using (id) join t5 using (id);
                                                         QUERY PLAN                                                           
-------------------------------------------------------------------------------------------------------------------------------
 Merge Join  (cost=617.21..1482900.86 rows=83256006 width=228)
   Merge Cond: (t5.id = t2.id)
   ->  Sort  (cost=88.17..91.35 rows=1270 width=36)
         Sort Key: t5.id
         ->  Seq Scan on t5  (cost=0.00..22.70 rows=1270 width=36)
   ->  Materialize  (cost=529.03..266744.20 rows=13111182 width=216)
         ->  Merge Join  (cost=529.03..233966.24 rows=13111182 width=216)
               Merge Cond: (t6.id = t2.id)
               ->  Sort  (cost=88.17..91.35 rows=1270 width=36)
                     Sort Key: t6.id
                     ->  Seq Scan on t6  (cost=0.00..22.70 rows=1270 width=36)
               ->  Materialize  (cost=440.86..42365.87 rows=2064753 width=180)
                     ->  Merge Join  (cost=440.86..37203.99 rows=2064753 width=180)
                           Merge Cond: (t7.id = t2.id)
                           ->  Sort  (cost=88.17..91.35 rows=1270 width=36)
                                 Sort Key: t7.id
                                 ->  Seq Scan on t7  (cost=0.00..22.70 rows=1270 width=36)
                           ->  Materialize  (cost=352.69..6951.07 rows=325158 width=144)
                                 ->  Merge Join  (cost=352.69..6138.17 rows=325158 width=144)
                                       Merge Cond: (t4.id = t2.id)
                                       ->  Sort  (cost=88.17..91.35 rows=1270 width=36)
                                             Sort Key: t4.id
                                             ->  Seq Scan on t4  (cost=0.00..22.70 rows=1270 width=36)
                                       ->  Materialize  (cost=264.52..1294.30 rows=51206 width=108)
                                             ->  Merge Join  (cost=264.52..1166.28 rows=51206 width=108)
                                                   Merge Cond: (t3.id = t2.id)
                                                   ->  Sort  (cost=88.17..91.35 rows=1270 width=36)
                                                         Sort Key: t3.id
                                                         ->  Seq Scan on t3  (cost=0.00..22.70 rows=1270 width=36)
                                                   ->  Materialize  (cost=176.34..323.83 rows=8064 width=72)
                                                         ->  Merge Join  (cost=176.34..303.67 rows=8064 width=72)
                                                               Merge Cond: (t2.id = t1.id)
                                                               ->  Sort  (cost=88.17..91.35 rows=1270 width=36)
                                                                     Sort Key: t2.id
                                                                     ->  Seq Scan on t2  (cost=0.00..22.70 rows=1270 width=36)
                                                               ->  Sort  (cost=88.17..91.35 rows=1270 width=36)
                                                                     Sort Key: t1.id
                                                                     ->  Seq Scan on t1  (cost=0.00..22.70 rows=1270 width=36)
(38 rows)
end;
```

或者设置会话级别的join_collapse_limit=1;

```plsql
set join_collapse_limit=1;
set geqo=off;
postgres=# explain select * from t2 join t1 using (id) join t3 using (id) join t4 using (id) join t7 using (id) join t6 using (id) join t5 using (id);
                                                          QUERY PLAN                                                           
-------------------------------------------------------------------------------------------------------------------------------
 Merge Join  (cost=617.21..1482900.86 rows=83256006 width=228)
   Merge Cond: (t5.id = t2.id)
   ->  Sort  (cost=88.17..91.35 rows=1270 width=36)
         Sort Key: t5.id
         ->  Seq Scan on t5  (cost=0.00..22.70 rows=1270 width=36)
   ->  Materialize  (cost=529.03..266744.20 rows=13111182 width=216)
         ->  Merge Join  (cost=529.03..233966.24 rows=13111182 width=216)
               Merge Cond: (t6.id = t2.id)
               ->  Sort  (cost=88.17..91.35 rows=1270 width=36)
                     Sort Key: t6.id
                     ->  Seq Scan on t6  (cost=0.00..22.70 rows=1270 width=36)
               ->  Materialize  (cost=440.86..42365.87 rows=2064753 width=180)
                     ->  Merge Join  (cost=440.86..37203.99 rows=2064753 width=180)
                           Merge Cond: (t7.id = t2.id)
                           ->  Sort  (cost=88.17..91.35 rows=1270 width=36)
                                 Sort Key: t7.id
                                 ->  Seq Scan on t7  (cost=0.00..22.70 rows=1270 width=36)
                           ->  Materialize  (cost=352.69..6951.07 rows=325158 width=144)
                                 ->  Merge Join  (cost=352.69..6138.17 rows=325158 width=144)
                                       Merge Cond: (t4.id = t2.id)
                                       ->  Sort  (cost=88.17..91.35 rows=1270 width=36)
                                             Sort Key: t4.id
                                             ->  Seq Scan on t4  (cost=0.00..22.70 rows=1270 width=36)
                                       ->  Materialize  (cost=264.52..1294.30 rows=51206 width=108)
                                             ->  Merge Join  (cost=264.52..1166.28 rows=51206 width=108)
                                                  Merge Cond: (t3.id = t2.id)
                                                   ->  Sort  (cost=88.17..91.35 rows=1270 width=36)
                                                         Sort Key: t3.id
                                                         ->  Seq Scan on t3  (cost=0.00..22.70 rows=1270 width=36)
                                                   ->  Materialize  (cost=176.34..323.83 rows=8064 width=72)
                                                         ->  Merge Join  (cost=176.34..303.67 rows=8064 width=72)
                                                               Merge Cond: (t2.id = t1.id)
                                                               ->  Sort  (cost=88.17..91.35 rows=1270 width=36)
                                                                     Sort Key: t2.id
                                                                     ->  Seq Scan on t2  (cost=0.00..22.70 rows=1270 width=36)
                                                               ->  Sort  (cost=88.17..91.35 rows=1270 width=36)
                                                                     Sort Key: t1.id
                                                                     ->  Seq Scan on t1  (cost=0.00..22.70 rows=1270 width=36)
(38 rows)
```

如何通过优化器获得最好的JOIN顺序？
 通常可以将join_collapse_limit设置为一个很大的值，然后查看执行计划，根据JOIN顺序修改SQL语句。
 例如

```plsql
postgres=# set join_collapse_limit=100;
SET
postgres=# set geqo=off;
SET
postgres=# explain select * from t2 join t1 using (id) join t3 using (id) join t4 using (id) join t7 using (id) join t6 using (id) join t5 using (id);
                                        QUERY PLAN                                         
-------------------------------------------------------------------------------------------
 Merge Join  (cost=617.21..1255551.94 rows=83256006 width=228)
   Merge Cond: (t2.id = t4.id)
   ->  Merge Join  (cost=264.52..1166.28 rows=51206 width=108)
         Merge Cond: (t3.id = t2.id)
         ->  Sort  (cost=88.17..91.35 rows=1270 width=36)
               Sort Key: t3.id
               ->  Seq Scan on t3  (cost=0.00..22.70 rows=1270 width=36)
         ->  Materialize  (cost=176.34..323.83 rows=8064 width=72)
               ->  Merge Join  (cost=176.34..303.67 rows=8064 width=72)
                     Merge Cond: (t2.id = t1.id)
                     ->  Sort  (cost=88.17..91.35 rows=1270 width=36)
                           Sort Key: t2.id
                           ->  Seq Scan on t2  (cost=0.00..22.70 rows=1270 width=36)
                     ->  Sort  (cost=88.17..91.35 rows=1270 width=36)
                          Sort Key: t1.id
                           ->  Seq Scan on t1  (cost=0.00..22.70 rows=1270 width=36)
   ->  Materialize  (cost=352.69..6317.49 rows=325158 width=144)
         ->  Merge Join  (cost=352.69..5504.60 rows=325158 width=144)
               Merge Cond: (t4.id = t6.id)
               ->  Merge Join  (cost=176.34..303.67 rows=8064 width=72)
                     Merge Cond: (t4.id = t7.id)
                     ->  Sort  (cost=88.17..91.35 rows=1270 width=36)
                           Sort Key: t4.id
                           ->  Seq Scan on t4  (cost=0.00..22.70 rows=1270 width=36)
                     ->  Sort  (cost=88.17..91.35 rows=1270 width=36)
                           Sort Key: t7.id
                           ->  Seq Scan on t7  (cost=0.00..22.70 rows=1270 width=36)
               ->  Materialize  (cost=176.34..323.83 rows=8064 width=72)
                    ->  Merge Join  (cost=176.34..303.67 rows=8064 width=72)
                           Merge Cond: (t6.id = t5.id)
                           ->  Sort  (cost=88.17..91.35 rows=1270 width=36)
                                 Sort Key: t6.id
                                 ->  Seq Scan on t6  (cost=0.00..22.70 rows=1270 width=36)
                           ->  Sort  (cost=88.17..91.35 rows=1270 width=36)
                                 Sort Key: t5.id
                                 ->  Seq Scan on t5  (cost=0.00..22.70 rows=1270 width=36)
(36 rows)
```

修改SQL，固定为最佳JOIN顺序。

```plsql
postgres=# set join_collapse_limit=1;
SET
postgres=# set geqo=off;
SET
explain select * from ((t4 join t7 using (id)) join (t6 join t5 using (id)) using (id)) join (t3 join (t2 join t1 using (id)) using (id)) using (id);
postgres=# explain select * from ((t4 join t7 using (id)) join (t6 join t5 using (id)) using (id)) join (t3 join (t2 join t1 using (id)) using (id)) using (id);
                                        QUERY PLAN                                         
-------------------------------------------------------------------------------------------
 Merge Join  (cost=617.21..1255482.81 rows=83245594 width=228)
   Merge Cond: (t2.id = t4.id)
   ->  Merge Join  (cost=264.52..1166.28 rows=51206 width=108)
         Merge Cond: (t3.id = t2.id)
         ->  Sort  (cost=88.17..91.35 rows=1270 width=36)
               Sort Key: t3.id
               ->  Seq Scan on t3  (cost=0.00..22.70 rows=1270 width=36)
         ->  Materialize  (cost=176.34..323.83 rows=8064 width=72)
               ->  Merge Join  (cost=176.34..303.67 rows=8064 width=72)
                     Merge Cond: (t2.id = t1.id)
                     ->  Sort  (cost=88.17..91.35 rows=1270 width=36)
                           Sort Key: t2.id
                           ->  Seq Scan on t2  (cost=0.00..22.70 rows=1270 width=36)
                     ->  Sort  (cost=88.17..91.35 rows=1270 width=36)
                           Sort Key: t1.id
                           ->  Seq Scan on t1  (cost=0.00..22.70 rows=1270 width=36)
   ->  Materialize  (cost=352.69..6317.45 rows=325140 width=144)
         ->  Merge Join  (cost=352.69..5504.60 rows=325140 width=144)
               Merge Cond: (t4.id = t6.id)
               ->  Merge Join  (cost=176.34..303.67 rows=8064 width=72)
                     Merge Cond: (t4.id = t7.id)
                     ->  Sort  (cost=88.17..91.35 rows=1270 width=36)
                           Sort Key: t4.id
                           ->  Seq Scan on t4  (cost=0.00..22.70 rows=1270 width=36)
                     ->  Sort  (cost=88.17..91.35 rows=1270 width=36)
                           Sort Key: t7.id
                           ->  Seq Scan on t7  (cost=0.00..22.70 rows=1270 width=36)
               ->  Materialize  (cost=176.34..323.83 rows=8064 width=72)
                     ->  Merge Join  (cost=176.34..303.67 rows=8064 width=72)
                           Merge Cond: (t6.id = t5.id)
                           ->  Sort  (cost=88.17..91.35 rows=1270 width=36)
                                 Sort Key: t6.id
                                 ->  Seq Scan on t6  (cost=0.00..22.70 rows=1270 width=36)
                           ->  Sort  (cost=88.17..91.35 rows=1270 width=36)
                                 Sort Key: t5.id
                                 ->  Seq Scan on t5  (cost=0.00..22.70 rows=1270 width=36)
(36 rows)
```

【推荐】PG优化器可以提升子查询，转换为JOIN，以获得更好的执行计划，但是如何强制优化器使用子查询呢 ？
 仅当子查询的数量小于from_collapse_limit时，这些子查询才会被提升为JOIN子句，超过的部分不会被提升为JOIN子句。
 同样需要考虑GEQO的设置，如果你不想使用遗传算法，可以设置geqo=off;
 要固定FROM子查询，两个设置即可from_collapse_limit=1, geqo=off;
 例如

```plsql
postgres=# set from_collapse_limit=1;  -- 这一不会提升子查询了, 但是JOIN顺序还是可能变化的，需要通过join_collapse_limit=1来设置
SET
postgres=# set geqo=off;
SET
postgres=# explain select * from t1 join t2 using (id) join (select * from t4) t4 using (id) join (select * from t6) t6 using (id) join (select * from t5) t5 using (id) join (select * from t3) t3 using (id);
                                                    QUERY PLAN                                                     
-------------------------------------------------------------------------------------------------------------------
 Merge Join  (cost=529.03..233966.24 rows=13111182 width=196)
   Merge Cond: (t3.id = t1.id)
   ->  Sort  (cost=88.17..91.35 rows=1270 width=36)
         Sort Key: t3.id
         ->  Seq Scan on t3  (cost=0.00..22.70 rows=1270 width=36)
   ->  Materialize  (cost=440.86..42365.87 rows=2064753 width=180)
         ->  Merge Join  (cost=440.86..37203.99 rows=2064753 width=180)
               Merge Cond: (t5.id = t1.id)
               ->  Sort  (cost=88.17..91.35 rows=1270 width=36)
                     Sort Key: t5.id
                     ->  Seq Scan on t5  (cost=0.00..22.70 rows=1270 width=36)
               ->  Materialize  (cost=352.69..6951.07 rows=325158 width=144)
                     ->  Merge Join  (cost=352.69..6138.17 rows=325158 width=144)
                           Merge Cond: (t6.id = t1.id)
                           ->  Sort  (cost=88.17..91.35 rows=1270 width=36)
                                 Sort Key: t6.id
                                 ->  Seq Scan on t6  (cost=0.00..22.70 rows=1270 width=36)
                           ->  Materialize  (cost=264.52..1294.30 rows=51206 width=108)
                                 ->  Merge Join  (cost=264.52..1166.28 rows=51206 width=108)
                                       Merge Cond: (t4.id = t1.id)
                                       ->  Sort  (cost=88.17..91.35 rows=1270 width=36)
                                             Sort Key: t4.id
                                             ->  Seq Scan on t4  (cost=0.00..22.70 rows=1270 width=36)
                                       ->  Materialize  (cost=176.34..323.83 rows=8064 width=72)
                                             ->  Merge Join  (cost=176.34..303.67 rows=8064 width=72)
                                                   Merge Cond: (t1.id = t2.id)
                                                   ->  Sort  (cost=88.17..91.35 rows=1270 width=36)
                                                         Sort Key: t1.id
                                                         ->  Seq Scan on t1  (cost=0.00..22.70 rows=1270 width=36)
                                                   ->  Sort  (cost=88.17..91.35 rows=1270 width=36)
                                                         Sort Key: t2.id
                                                         ->  Seq Scan on t2  (cost=0.00..22.70 rows=1270 width=36)
(32 rows)
```

如何通过优化器判断FROM子句是否需要提升以得到好的执行计划？
 通过优化器的指导，调整SQL即可
 例如

```plsql
postgres=# set join_collapse_limit=100;
SET
postgres=# set from_collapse_limit=100;
SET
postgres=# set geqo=off;
SET
postgres=# explain select * from t1 join t2 using (id) join (select * from t4) t4 using (id) join (select * from t6) t6 using (id) join (select * from t5) t5 using (id) join (select * from t3) t3 using (id);
                                        QUERY PLAN                                         
-------------------------------------------------------------------------------------------
 Merge Join  (cost=529.03..199114.66 rows=13111182 width=196)
   Merge Cond: (t1.id = t6.id)
   ->  Merge Join  (cost=264.52..1166.28 rows=51206 width=108)
         Merge Cond: (t4.id = t1.id)
         ->  Sort  (cost=88.17..91.35 rows=1270 width=36)
               Sort Key: t4.id
               ->  Seq Scan on t4  (cost=0.00..22.70 rows=1270 width=36)
         ->  Materialize  (cost=176.34..323.83 rows=8064 width=72)
               ->  Merge Join  (cost=176.34..303.67 rows=8064 width=72)
                     Merge Cond: (t1.id = t2.id)
                     ->  Sort  (cost=88.17..91.35 rows=1270 width=36)
                           Sort Key: t1.id
                           ->  Seq Scan on t1  (cost=0.00..22.70 rows=1270 width=36)
                     ->  Sort  (cost=88.17..91.35 rows=1270 width=36)
                           Sort Key: t2.id
                           ->  Seq Scan on t2  (cost=0.00..22.70 rows=1270 width=36)
   ->  Materialize  (cost=264.52..1294.30 rows=51206 width=108)
         ->  Merge Join  (cost=264.52..1166.28 rows=51206 width=108)
               Merge Cond: (t3.id = t6.id)
               ->  Sort  (cost=88.17..91.35 rows=1270 width=36)
                     Sort Key: t3.id
                     ->  Seq Scan on t3  (cost=0.00..22.70 rows=1270 width=36)
               ->  Materialize  (cost=176.34..323.83 rows=8064 width=72)
                     ->  Merge Join  (cost=176.34..303.67 rows=8064 width=72)
                           Merge Cond: (t6.id = t5.id)
                           ->  Sort  (cost=88.17..91.35 rows=1270 width=36)
                                 Sort Key: t6.id
                                 ->  Seq Scan on t6  (cost=0.00..22.70 rows=1270 width=36)
                           ->  Sort  (cost=88.17..91.35 rows=1270 width=36)
                                 Sort Key: t5.id
                                 ->  Seq Scan on t5  (cost=0.00..22.70 rows=1270 width=36)
(31 rows)
```

调整SQL如下

```plsql
explain select * from ((select * from t4) t4 join (t1 join t2 using (id)) using (id)) join ((select * from t3) t3 join ((select * from t6) t6 join (select * from t5) t5 using (id)) using (id)) using (id);
postgres=# set join_collapse_limit=1;
SET
postgres=# set from_collapse_limit=1;
SET
postgres=# set geqo=off;
SET
postgres=# explain select * from ((select * from t4) t4 join (t1 join t2 using (id)) using (id)) join ((select * from t3) t3 join ((select * from t6) t6 join (select * from t5) t5 using (id)) using (id)) using (id);
                                        QUERY PLAN                                         
-------------------------------------------------------------------------------------------
 Merge Join  (cost=529.03..199114.66 rows=13110272 width=196)
   Merge Cond: (t1.id = t6.id)
   ->  Merge Join  (cost=264.52..1166.28 rows=51206 width=108)
         Merge Cond: (t4.id = t1.id)
         ->  Sort  (cost=88.17..91.35 rows=1270 width=36)
               Sort Key: t4.id
               ->  Seq Scan on t4  (cost=0.00..22.70 rows=1270 width=36)
         ->  Materialize  (cost=176.34..323.83 rows=8064 width=72)
               ->  Merge Join  (cost=176.34..303.67 rows=8064 width=72)
                     Merge Cond: (t1.id = t2.id)
                     ->  Sort  (cost=88.17..91.35 rows=1270 width=36)
                           Sort Key: t1.id
                           ->  Seq Scan on t1  (cost=0.00..22.70 rows=1270 width=36)
                     ->  Sort  (cost=88.17..91.35 rows=1270 width=36)
                           Sort Key: t2.id
                           ->  Seq Scan on t2  (cost=0.00..22.70 rows=1270 width=36)
   ->  Materialize  (cost=264.52..1294.30 rows=51206 width=108)
         ->  Merge Join  (cost=264.52..1166.28 rows=51206 width=108)
               Merge Cond: (t3.id = t6.id)
               ->  Sort  (cost=88.17..91.35 rows=1270 width=36)
                     Sort Key: t3.id
                     ->  Seq Scan on t3  (cost=0.00..22.70 rows=1270 width=36)
               ->  Materialize  (cost=176.34..323.83 rows=8064 width=72)
                     ->  Merge Join  (cost=176.34..303.67 rows=8064 width=72)
                           Merge Cond: (t6.id = t5.id)
                           ->  Sort  (cost=88.17..91.35 rows=1270 width=36)
                                 Sort Key: t6.id
                                 ->  Seq Scan on t6  (cost=0.00..22.70 rows=1270 width=36)
                           ->  Sort  (cost=88.17..91.35 rows=1270 width=36)
                                 Sort Key: t5.id
                                 ->  Seq Scan on t5  (cost=0.00..22.70 rows=1270 width=36)
(31 rows)
```

【推荐】GIN索引的写优化，因为GIN的索引列通常是多值列，所以一条记录可能影响GIN索引的多个页，为了加快数据插入和更新删除的速度，建议打开fastupdate，同时设置合适的gin_pending_list_limit(单位KB)。
 这么做的原理是，当变更GIN索引时，先记录在PENDING列表，而不是立即合并GIN索引。从而提升性能。
 例如

```plsql
create index idx_1 on tbl using gin (tsvector) with (fastupdate=on, gin_pending_list_limit=10240)
```

【推荐】b-tree索引优化，不建议对频繁访问的数据上使用非常离散的数据，例如UUID作为索引，索引页会频繁的分裂，重锁，重IO和CPU开销都比较高。
 如何降低频繁更新索引字段的索引页IO，设置fillfactor为一个合适的值，默认90已经适合大部分场景。

【推荐】BRIN索引优化，根据数据的相关性，以及用户需求的查询的范围，设置合适的pages_per_range=n。
 例如用户经常需要按范围查询10万条记录，通过评估，发现10万条记录通常分布在100个数据页中，那么可以设置pages_per_range=100。
 评估方法
 如何获取平均每个页存了多少条记录。

```plsql
analyze tbl;
select reltuples/relpages from tbl;
```
